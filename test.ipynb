{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bit1e9b5f95686b4639a982d07c8227ee53",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "INGRESS_GATEWAY_SERVICE=$(kubectl get svc --namespace istio-system --selector=\"app=istio-ingressgateway\" --output jsonpath='{.items[0].metadata.name}')\n",
    "kubectl port-forward --namespace istio-system svc/${INGRESS_GATEWAY_SERVICE} 8080:80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "iris-test.explainable-ml-engine.example.com\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $(kubectl get inferenceservice iris-test -n explainable-ml-engine -o jsonpath='{.status.url}' | cut -d \"/\" -f 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\"predictions\": [1, 1]}  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0*   Trying ::1...\n",
      "* TCP_NODELAY set\n",
      "* Connected to localhost (::1) port 8080 (#0)\n",
      "> POST /v1/models/iris-test:predict HTTP/1.1\n",
      "> Host: iris-test.explainable-ml-engine.example.com\n",
      "> User-Agent: curl/7.64.1\n",
      "> Accept: */*\n",
      "> Content-Length: 65\n",
      "> Content-Type: application/x-www-form-urlencoded\n",
      "> \n",
      "} [65 bytes data]\n",
      "* upload completely sent off: 65 out of 65 bytes\n",
      "< HTTP/1.1 200 OK\n",
      "< content-length: 23\n",
      "< content-type: application/json; charset=UTF-8\n",
      "< date: Thu, 12 Nov 2020 20:25:06 GMT\n",
      "< server: istio-envoy\n",
      "< x-envoy-upstream-service-time: 119\n",
      "< \n",
      "{ [23 bytes data]\n",
      "100    88  100    23  100    65    150    424 --:--:-- --:--:-- --:--:--   575\n",
      "* Connection #0 to host localhost left intact\n",
      "* Closing connection 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export MODEL_NAME=iris-test\n",
    "export INGRESS_HOST=localhost\n",
    "export INGRESS_PORT=8080\n",
    "export SERVICE_HOSTNAME=iris-test.explainable-ml-engine.example.com\n",
    "curl -v -H \"Host: ${SERVICE_HOSTNAME}\" http://${INGRESS_HOST}:${INGRESS_PORT}/v1/models/$MODEL_NAME:predict -d '{\"instances\": [[6.8,  2.8,  4.8,  1.4], [6.0,  3.4,  4.5,  1.6]]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}